translator_p = str.maketrans('', '', string.punctuation)
translator_d = str.maketrans('', '', string.digits)
stop_words = set(stopwords.words('english'))
word_lem = WordNetLemmatizer()
word_stem = PorterStemmer()

def clean(text):
    text = text.strip() #strip
    text = text.lower()
    text = text.translate(translator_p)
    text = text.translate(translator_d)
    return text

clean_vec = np.vectorize(clean)

def clean_lemma(text):
    return " ".join([word_lem.lemmatize(w) for w in iter(word_tokenize(text)) if w not in stop_words]) ## remove stopwords
clean_lemma_vec = np.vectorize(clean_lemma)

def clean_stem(text):
    return " ".join([word_stem.stem(w) for w in iter(word_tokenize(text)) if w not in stop_words]) ## remove stopwords
clean_stem_vec = np.vectorize(clean_stem)
